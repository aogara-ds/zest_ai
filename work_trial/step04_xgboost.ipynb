{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac407935",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d58c7e",
   "metadata": {},
   "source": [
    "This notebook implements a gradient-boosted decision tree ensemble via XGBoost. The model uses 63 input features to predict the single binary outcome of whether or not a particular loan is bad. 1771 models are built with unique hyperparameters to find the model structure that maximizes performance on key target metrics. The highest performing model correctly identifies whether a loan will be good or bad in 60% of validation set cases. \n",
    "\n",
    "Data is split into three sets: train, validation, and test. Individual models are fitted on the training data. Performance metrics are reported on validation data, which is not used in training. Once a model has been chosen, test data will provide an estimate of its performance in future use. Cross-validation is used to generate five unique splits of training and validation data for use in fitting, providing performance estimates less biased by the individual dataset. \n",
    "\n",
    "Six hyperparameters are tuned in order to optimize performance of the model (tested values in parentheses):\n",
    "* Maximum Tree Depth: How many levels of splits can an individual tree contain? (2, 4, 8, 16, 32)\n",
    "* Minimum Child Weight: What is the minimum sample size of a new node/leaf? (1, 4, 8, 12, 16, 20, 24, 48)\n",
    "* Subsample Fraction: What fraction of the training data is each tree trained on? (0.70, 1.00)\n",
    "* Lambda: Weight multiplier on the L2 regularization parameter. (0, 0.5, 1)\n",
    "* Gamma: Prune nodes below the given threshold of performance gain. (0, 0.5, 1, 5, 10, 50, 100)\n",
    "* Eta: Reduce the weight of each successive tree by the given multiplier. (0.001, 0.01, 0.05, 0.1, 0.25, 0.5)\n",
    "\n",
    "Six model performance metrics are tracked for analysis in the next notebook:\n",
    "* Brier Score (equivalent to RMSE)\n",
    "* AUC-ROC Curve\n",
    "* Precision\n",
    "* Recall\n",
    "* Accuracy\n",
    "* Balanced Accuracy\n",
    "\n",
    "Future work on this question would include the specification of a custom scoring mechanism for fair lending metrics. By deriving each customer's demographic data from their application information, we could measure the default probabilities assigned to customers of different protected groups. We could compare their overall probabilities of default, as well as probabilities of false positive and false negative, in order to estimate the fair lending impact of our model.\n",
    "\n",
    "\n",
    "Paper on XGBoost for Default Prediction: https://www.terry.uga.edu/sites/default/files/inline-files/Albanesi_Domossy_2021.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c985f97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import xgboost\n",
    "import tqdm\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from xgboost import XGBClassifier, DMatrix\n",
    "import multiprocessing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c302b302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data and data dictionary\n",
    "data = pd.read_pickle('output_data/02_data.pkl')\n",
    "\n",
    "data_dict = pd.read_pickle('output_data/02_data_dict.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789468e7",
   "metadata": {},
   "source": [
    "### Designate Feature Sets using Data Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b759898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate feature set\n",
    "\n",
    "feature_set = {\n",
    "    'all': data_dict.loc[data_dict['potential_feature']==True, \n",
    "                               'variable'].values,\n",
    "    'no_credit': data_dict.loc[data_dict['eda_category'].isin(('personal_finance', 'other_info')),\n",
    "                               'variable'].values,\n",
    "    'significant': data_dict.loc[data_dict['pearson_p'] < 0.05, \n",
    "                               'variable'].values,\n",
    "    'significant_no_credit': data_dict.loc[(data_dict['pearson_p'] < 0.05) &\n",
    "        (data_dict['eda_category'].isin(('personal_finance', 'other_info'))),\n",
    "                                                          'variable'].values,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1a8b8d",
   "metadata": {},
   "source": [
    "### Train, Test, and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28a05d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chronological method achieves Train-Val-Test split of approximately 85-15 proportions.\n",
      "Validation sets consisting of 20% of training data will be dynamically generated later.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "train    555\n",
       "test      95\n",
       "Name: model_set, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into training, validation, and testing data\n",
    "# Split chronologically to resolve the look-ahead problem\n",
    "\n",
    "# Generate a new column to track the observation's model dataset category\n",
    "data['model_set'] = 'train'\n",
    "\n",
    "# Test Data comes from March 2011\n",
    "data.loc[data['application_month_of_cycle'] == 6, 'model_set'] = 'test'\n",
    "\n",
    "# Display results\n",
    "print(\"Chronological method achieves Train-Val-Test split of approximately 85-15 proportions.\")\n",
    "print(\"Validation sets consisting of 20% of training data will be dynamically generated later.\")\n",
    "data['model_set'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a74b2c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into x and y data\n",
    "# Use the list of potential features from the data dictionary\n",
    "X_train = data.loc[data['model_set'] == 'train']\n",
    "X_test = data.loc[data['model_set'] == 'test']\n",
    "\n",
    "# Designate Y data for train, validation, and test\n",
    "y_train = data.loc[data['model_set'] == 'train', 'bad']\n",
    "y_test = data.loc[data['model_set'] == 'test', 'bad']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e830afd",
   "metadata": {},
   "source": [
    "## Sample Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9be7b3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure constant model settings\n",
    "settings = {\n",
    "    'booster': ['gbtree'], \n",
    "    'objective': ['binary:logistic'],\n",
    "    'eval_metric': ['logloss'], # TODO: Suppress the warning down there. \n",
    "    'nthread': [multiprocessing.cpu_count()]\n",
    "}\n",
    "\n",
    "# Configure hyperparameters\n",
    "# Currently building 1728 models\n",
    "hypers = {\n",
    "    'eta': [0.01, .10, .25, .50], # learning rate, reduces size of error adjustment\n",
    "    'gamma': [0, 0.5, 5], # Raise to reduce overfitting (prevents low-magnitude leaves)    \n",
    "    'min_child_weight': [1, 4, 16], # Raise to eliminate leaves with low sample weight\n",
    "    'subsample': [.7, 1], # Each boosting round trains on X% of the training data\n",
    "    'max_depth': [2, 4, 8], # Maximum depth of a single tree\n",
    "    'reg_lambda': [0, 1], # L2 regularization\n",
    "}\n",
    "\n",
    "single_hyper = {k: v[0] for k, v in hypers.items()}\n",
    "\n",
    "# Monitor hypers chosen by XGB\n",
    "monitor_hypers = {\n",
    "    'num_pbuffer': None,\n",
    "    'num_feature': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b6b8bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_dict = settings.copy()\n",
    "new_simple_dict = {\n",
    "    'eta': [.10], # learning rate, reduces size of error adjustment\n",
    "    'gamma': [0], # Raise to reduce overfitting (prevents low-magnitude leaves)    \n",
    "    'min_child_weight': [1, 4, 16], # Raise to eliminate leaves with low sample weight\n",
    "    'subsample': [.7], # Each boosting round trains on X% of the training data\n",
    "    'max_depth': [2, 4, 8], # Maximum depth of a single tree\n",
    "    'reg_lambda': [0, 1], # L2 regularization\n",
    "}\n",
    "simple_dict.update(new_simple_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8364771d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aidan\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5368421052631579\n"
     ]
    }
   ],
   "source": [
    "tree = XGBClassifier()\n",
    "params = settings.update(hypers)\n",
    "num_round = [2, 4, 8, 16]\n",
    "\n",
    "tree = tree.fit(X = X_train[feature_set['significant_no_credit']], \n",
    "                y = y_train,\n",
    "                eval_metric='rmse')\n",
    "\n",
    "y_pred = tree.predict(X_test[feature_set['significant_no_credit']])\n",
    "\n",
    "print(f\"Accuracy: {(y_test == y_pred).sum() / (y_test == y_pred).count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced5ea53",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4687f8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccb71a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure constant model settings\n",
    "params = {\n",
    "    'booster': ['gbtree'], \n",
    "    'objective': ['binary:logistic'],\n",
    "    'eval_metric': ['logloss'], # TODO: Suppress the warning down there. \n",
    "    'nthread': [multiprocessing.cpu_count()],\n",
    "    'eta': [0.01, .10, .25, .50], # learning rate, reduces size of error adjustment\n",
    "    'gamma': [0, 0.5, 5], # Raise to reduce overfitting (prevents low-magnitude leaves)    \n",
    "    'min_child_weight': [1, 4, 16], # Raise to eliminate leaves with low sample weight\n",
    "    'subsample': [.7, 1], # Each boosting round trains on X% of the training data\n",
    "    'max_depth': [2, 4, 8], # Maximum depth of a single tree\n",
    "    'reg_lambda': [0, 1], # L2 regularization\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8772a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=estimator,\n",
    "    param_grid=params,\n",
    "    scoring = ['neg_brier_score', 'accuracy', 'balanced_accuracy', 'precision', 'recall', 'roc_auc'],\n",
    "    n_jobs = multiprocessing.cpu_count(),\n",
    "    cv = 5,\n",
    "    verbose=10,\n",
    "    refit = 'neg_brier_score'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81e7837",
   "metadata": {},
   "source": [
    "EDIT: Final commit does not run time-intensive steps. I reran all the notebooks before committing to check for errors, but given that the results of the grid search had already been pickles, I skipped these few cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b87aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each potential set of features\n",
    "for name, features in feature_set.items():\n",
    "    \n",
    "    # Fit each classifier in the grid search\n",
    "    grid_search.fit(X_train[features], y_train)\n",
    "    \n",
    "    # Save performance with dynamic naming\n",
    "    performance = pd.DataFrame(grid_search.cv_results_)\n",
    "    performance.to_pickle(f'output_data/04_{name}_performance_0001.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb88006",
   "metadata": {},
   "source": [
    "## Second Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b275d7d",
   "metadata": {},
   "source": [
    "After a round of performance evaluation, I've picked some hyperparameters and come back to test more. Thanks to the scoring of our earlier models, we know our tuning is improving model performance on the validation set. \n",
    "\n",
    "Here are the hyperparameters we'd like to continue improving upon:\n",
    "\n",
    "* Maximum Depth of a Tree\n",
    "* Minimum Weight of a Leaf\n",
    "* Gamma Parameter\n",
    "* Eta Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b1107fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_0002 = {\n",
    "    'booster': ['gbtree'], \n",
    "    'objective': ['binary:logistic'],\n",
    "    'eval_metric': ['logloss'], # TODO: Suppress the warning down there. \n",
    "    'nthread': [multiprocessing.cpu_count()],\n",
    "    'eta': [.05, .01, .001, .0001], \n",
    "    'gamma': [1, 10, 50, 100], # Raise to reduce overfitting (prevents low-magnitude leaves)    \n",
    "    'min_child_weight': [8, 24, 48], # Raise to eliminate leaves with low sample weight\n",
    "    'max_depth': [4, 8, 16, 32], # Maximum depth of a single tree\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fff566ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=estimator,\n",
    "    param_grid=params_0002,\n",
    "    scoring = ['neg_brier_score', 'accuracy', 'balanced_accuracy', 'precision', 'recall', 'roc_auc'],\n",
    "    n_jobs = multiprocessing.cpu_count(),\n",
    "    cv = 5,\n",
    "    verbose=10,\n",
    "    refit = 'neg_brier_score'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3cc232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each potential set of features\n",
    "for name, features in feature_set.items():\n",
    "    \n",
    "    # Fit each classifier in the grid search\n",
    "    grid_search.fit(X_train[features], y_train)\n",
    "    \n",
    "    # Save performance with dynamic naming\n",
    "    performance = pd.DataFrame(grid_search.cv_results_)\n",
    "    performance.to_pickle(f'output_data/04_{name}_performance_0002.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579c1502",
   "metadata": {},
   "source": [
    "## Third Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a2a3d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure constant model settings\n",
    "params_0003 = {\n",
    "    'booster': ['gbtree'], \n",
    "    'objective': ['binary:logistic'],\n",
    "    'eval_metric': ['logloss'], # TODO: Suppress the warning down there. \n",
    "    'nthread': [multiprocessing.cpu_count()],\n",
    "    'eta': [0.08, .12, .0005, .4], # learning rate, reduces size of error adjustment\n",
    "    'gamma': [0.25, .75, 2, 8], # Raise to reduce overfitting (prevents low-magnitude leaves)    \n",
    "    'min_child_weight': [8, 12, 20], # Raise to eliminate leaves with low sample weight\n",
    "    'subsample': [.7, 1], # Each boosting round trains on X% of the training data\n",
    "    'max_depth': [2, 4, 8], # Maximum depth of a single tree\n",
    "    'reg_lambda': [0, 0.5, 1, 1.5], # L2 regularization\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6be53642",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=estimator,\n",
    "    param_grid=params_0003,\n",
    "    scoring = ['neg_brier_score', 'accuracy', 'balanced_accuracy', 'precision', 'recall', 'roc_auc'],\n",
    "    n_jobs = multiprocessing.cpu_count(),\n",
    "    cv = 5,\n",
    "    verbose=10,\n",
    "    refit = 'neg_brier_score'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c52a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each potential set of features\n",
    "for name, features in feature_set.items():\n",
    "    \n",
    "    # Fit each classifier in the grid search\n",
    "    grid_search.fit(X_train[features], y_train)\n",
    "    \n",
    "    # Save performance with dynamic naming\n",
    "    performance = pd.DataFrame(grid_search.cv_results_)\n",
    "    performance.to_pickle(f'output_data/04_{name}_performance_0003.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c279a1ce",
   "metadata": {},
   "source": [
    "# Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e1b7f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data\n",
    "X_train.to_pickle('output_data/04_X_train.pkl')\n",
    "X_test.to_pickle('output_data/04_X_test.pkl')\n",
    "\n",
    "y_train.to_pickle('output_data/04_y_train.pkl')\n",
    "y_test.to_pickle('output_data/04_y_test.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
